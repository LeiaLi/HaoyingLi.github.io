<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- <link rel="icon" type="image/x-svg" href="./images/nvidia.svg"> -->
    <script src="https://unpkg.com/typewriter-effect@latest/dist/core.js"></script>
    <script src="https://kit.fontawesome.com/8290b48404.js" crossorigin="anonymous"></script>
    <link
    rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"
  />
    <link rel="stylesheet" href="./dist/style.css">

    <title>Adaptive Window Pruning for Efficient Local Motion Deblurring</title>
</head>
<body>
    <div class="main container">
        <!-- <nav class="menu">
            <ul>
                <li><a href="#news">News</a></li>
                <li><a href="https://arxiv.org/abs/2112.07658">Paper</a></li>
            </ul>
        </nav> -->

        <div class="wrapper">
            <div class="wrapper-title">
                <div id="title">Adaptive Window Pruning for Efficient Local Motion Deblurring</div>
            </div>

            <div class="wrapper-crew">
                <div class="crew">
                    <ul>
                        <li class="wow animate__animated animate__fadeInDown"><a target="_blank" class="" href="https://leiali.github.io/">Haoying Li</a></li>
                        <li class="wow animate__animated animate__fadeInDown"><a target="_blank" class="" href="https://scholar.google.com/citations?user=0Z89rfUAAAAJ">Jixin Zhao</a></li>
                        <li class="wow animate__animated animate__fadeInDown"><a target="_blank" class="" href="https://shangchenzhou.com/">Shangchen Zhou</a></li>
                        <li class="wow animate__animated animate__fadeInUp"><a target="_blank" class="" href="https://ieeexplore.ieee.org/author/38081851500">Huajun Feng</a></li>
                        <li class="wow animate__animated animate__fadeInUp"><a target="_blank" class="" href="https://li-chongyi.github.io/">Chongyi Li</a></li>
                        <li class="wow animate__animated animate__fadeInUp"><a target="_blank" class="" href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a></li>
                    </ul>
                </div>
            </div>

            <div class="wrapper-main-download">
                <div class="main-download">
                    <figure>
                        <img src="img_source/images/affiliations.png" alt="" width="200">
                        <!-- <div class="download-btn">
                        <a class="wow animate__animated animate__lightSpeedInLeft" target="_blank" href="https://arxiv.org/abs/2112.07658"><i class="far fa-sticky-note"></i> Paper (ArXiv) </a>
                        <a class="wow animate__animated animate__lightSpeedInRight" target="_blank" href=""><i class="fas fa-file-code"></i> Code (to come)</a>
                    </div> -->
                </div>
            </div>

            <div class="wrapper-articles">
                <div class="article">

                </div>


                <!-- <div id="news" class="article">
                    <div class="title">
                        <span>News</span>
                    </div>
                    <div class="news-wrapper">
                        <ul>
                            <li><i class="fa-solid fa-rss"></i> [Jul 2022] Code is released under <a target="_blank" href="https://github.com/NVlabs/A-ViT">NVLabs</a>.</li>
                            <li><i class="fa-solid fa-rss"></i> [Mar 2022] Accpetance as <b> oral presentation</b>.</li>
                            <li><i class="fa-solid fa-rss"></i> [Mar 2022] Our paper has been accepted to <a target="_blank" href="https://cvpr2022.thecvf.com/">CVPR 2022</a>.</li>
                        </ul>
                    </div>
                </div> -->

                <div class="article">
                    <div class="title">
                        <span>Abstract</span>
                    </div>
                    <article>
                        <figure class="article-image">
                        <!-- <img class="wow animate__animated animate__fadeInLeft" src="./images/client_server.png" alt=""> -->
                        <!-- <figcaption>*Equal contribution.**Equal advising.</figcaption> -->
                        <img class="wow animate__animated animate__fadeInLeft" src="./img_source/images/motivation.png" alt="">
                        </figure>

                        <!-- <p> We propose LMD-ViT, a Transformer-based local motion deblurring method with an adaptive window pruning mechanism. We prune unnecessary windows based on the predicted blurriness confidence supervised by our blur region annotation. In this process, the feature maps are pruned at varying levels of granularity within blocks of different resolutions (as depicted in the 3rdï½ž5th visualizations in Row 1). Unlike global deblurring methods 
                            that modify global regions (i.e. Uformer), LMD-ViT performs dense computing only on the active windows of blurry regions. Consequently, local blurs are efficiently removed without distorting sharp regions, as shown in Row 2.</p> -->
                        <p> We introduce LMD-ViT, a Transformer-based local motion deblurring method with an
                            adaptive window pruning mechanism. We prune unnecessary windows based on the predicted 
                            blurriness confidence supervised by our blur region annotation. In this process, the 
                            feature maps are pruned at varying levels of granularity within blocks of different 
                            resolutions. The white masks in AdaWPT 5 to 8 denote tokens to be preserved, and regions 
                            without white masks are pruned. The grids denote window borders. Unlike global deblurring 
                            methods that modify global regions, LMD-ViT performs dense computing only on the active 
                            windows of blurry regions. Consequently, local blurs are efficiently removed without 
                            distorting sharp regions.</p>
                        </article>
                    <!-- <figure class="article-image"></figure> -->
                </div>
                <div class="article">
                    <div class="title">
                        <span>Key Approach</span>
                    </div>
                    <article>
                        <p>Local motion blur commonly occurs in real-world photography due to the mixing 
                            between moving objects and stationary backgrounds during exposure. Existing 
                            image deblurring methods predominantly focus on global deblurring, inadvertently
                            affecting the sharpness of backgrounds in locally blurred images and wasting 
                            unnecessary computation on sharp pixels, especially for high-resolution images. 
                            This paper aims to adaptively and efficiently restore high-resolution locally
                            blurred images. We propose a local motion deblurring vision Transformer (LMD-ViT)
                            built on adaptive window pruning Transformer blocks (AdaWPT). To focus deblurring 
                            on local regions and reduce computation, AdaWPT prunes unnecessary windows, 
                            only allowing the active windows to be involved in the deblurring processes. 
                            The pruning operation relies on the blurriness confidence predicted by a confidence 
                            predictor that is trained end-to-end using a reconstruction loss with Gumbel-Softmax 
                            re-parameterization and a pruning loss guided by annotated blur masks. Our method 
                            removes local motion blur effectively without distorting sharp regions, demonstrated 
                            by its exceptional perceptual and quantitative improvements compared to 
                            state-of-the-art methods. In addition, our approach substantially reduces FLOPs by 
                            66% and achieves more than a twofold increase in inference speed compared to 
                            Transformer-based deblurring methods.</p>
                    </article>
                    <figure class="article-image">
                        <img class="wow animate__animated animate__fadeInLeft" src="./img_source/images/network.png" alt="">
                        <figcaption>
                            <b>Architecture of LMD-ViT.</b> The proposed local motion deblurring vision Transformer 
                            (LMD-ViT) is a U-shaped network with an encoder stage, a bottleneck stage, and a decoder 
                            stage with skip connections. An in-projection/out-projection layer is placed at the 
                            beginning/end of the network to extract RGB images to feature maps or convert feature maps 
                            to RGB images. The encoder, bottleneck, and decoder include a series of adaptive 
                            window-token pruning Transformer blocks (AdaWPT) and down-sampling/up-sampling layers. 
                            As a key component, AdaWPT removes local blurs by a window pruning strategy with a confidence 
                            predictor, a decision layer, and several Transformer layers. It is trained with a reconstruction 
                            loss and a pruning loss constrained by our carefully annotated blur masks. AdaWPT can be 
                            applied in any encoder/decoder/bottom-neck block and is flexible to prune at different resolutions.  
                            In our proposed LMD-ViT, windows are pruned coarsely in low-resolution blocks and finely in 
                            high-resolution blocks. This strikes a balance between computational complexity and accuracy.
                        </figcaption>
                    <br>
                    </figure>
                    <!-- <figure class="article-image">
                        <img class="wow animate__animated animate__fadeInRight" src="./img_source/images/AdaWPT.png" alt="">
                        <figcaption>
                            <b>Structure of AdaWPT in training and inference phase.</b> There are two kinds of AdaWPT: AdaWPT-F and AdaWPT-P. AdaWPT-F predicts the confidence of blurriness (``C'') and pruning decisions (``D''), and AdaWPT-P follows the pruning decisions. Both AdaWPT-F and AdaWPT-P prune windows in Transformer layers. ``X'' denotes the feature map.
                        </figcaption>
                    </figure> -->

                    </figure>
                </div>
                <div class="article">
                    <div class="title">
                        <span>Deblurring Results</span>
                    </div>
                    <div align="center">
                    <div class="columns is-multiline is-centered">
                      <table>
                        <tr>
                          <td style="padding:5px 5px 5px 5px;">
                              <img src='img_source/fig/blur1.png' onmouseover="this.src='img_source/fig/deblur1.png';" onmouseout="this.src='img_source/fig/blur1.png';"  height="256" width="256" />
                          </td>
                          <td style="padding:5px 5px 5px 5px;">
                              <img src='img_source/fig/blur2.png' onmouseover="this.src='img_source/fig/deblur2.png';" onmouseout="this.src='img_source/fig/blur2.png';"  height="256" width="256" />
                          </td>
                          <td style="padding:5px 5px 5px 5px;">
                              <img src='img_source/fig/blur3.png' onmouseover="this.src='img_source/fig/deblur3.png';" onmouseout="this.src='img_source/fig/blur3.png';"  height="256" width="256" />
                          </td>
                          <td style="padding:5px 5px 5px 5px;">
                              <img src='img_source/fig/blur4.png' onmouseover="this.src='img_source/fig/deblur4.png';" onmouseout="this.src='img_source/fig/blur4.png';"  height="256" width="256" />
                          </td>	
                        </tr>
                        <!-- <tr>
                            <td style="padding:5px 5px 5px 5px;">
                                <img src='Data/deblur_results/f03_20211218105433-1_cam2_blur_c.png' onmouseover="this.src='Data/deblur_results/f03_20211218105433-1_cam2_deblur_c.png';" onmouseout="this.src='Data/deblur_results/f03_20211218105433-1_cam2_blur_c.png';"  height="256" width="256" />
                            </td>
                            <td style="padding:5px 5px 5px 5px;">
                                <img src='Data/deblur_results/f06_20211226153610-5_cam2_blur_c.png' onmouseover="this.src='Data/deblur_results/f06_20211226153610-5_cam2_deblur_c.png';" onmouseout="this.src='Data/deblur_results/f06_20211226153610-5_cam2_blur_c.png';"  height="256" width="256" />
                            </td>
                            <td style="padding:5px 5px 5px 5px;">
                                <img src='Data/deblur_results/f05_20211230122043-1_cam2_blur_c.png' onmouseover="this.src='Data/deblur_results/f05_20211230122043-1_cam2_deblur_c.png';" onmouseout="this.src='Data/deblur_results/f05_20211230122043-1_cam2_blur_c.png';"  height="256" width="256" />
                            </td>
                            <td style="padding:5px 5px 5px 5px;">
                                <img src='Data/deblur_results/f07_20211230123704-9_cam2_blur_c.png' onmouseover="this.src='Data/deblur_results/f07_20211230123704-9_cam2_deblur_c.png';" onmouseout="this.src='Data/deblur_results/f07_20211230123704-9_cam2_blur_c.png';"  height="256" width="256" />
                            </td>
                          </tr> -->
                          
                      </table>
                    </div>
                    </div>
                    <div align="center">
                    <div class="columns is-multiline is-centered">
                        <p> MouseOver: LMD-ViT deblurred images</p>            
                        <p> MouseOut: Locally blurred images</p>
                    </div>
                    </div>
                </div>
            </div>

            <section class='section links-section'>
                <div class='section-title'>
                </div>
                <div class='details links-table'>
                    <table>
                        <tr>
                            <td>
                                <div class='links-container'>
                                    <a href='https://arxiv.org/abs/2306.14268' target="_blank"><img class='links-cover'src='./img_source/images/paper_cover.png' alt='PDF Cover' width="100"></a>
                                </div>
                            </td>
                            
                            <td>
                                <div class='links-container'>
                                    <a href='https://github.com/LeiaLi/LMD-ViT' target="_blank"><img class='links-cover'
                                            src='./img_source/images/github.png' alt='github icon' width="100"></a>
                                </div>
                            </td>
                            <td>
                                <div class='links-container'>
                                    <a href='https://drive.google.com/file/d/1PPXWxn7gYvqwHX301SuWmjI7IUUtqxab/view?usp=sharing' target="_blank"><img class='links-cover'
                                            src='./img_source/images/Google_Drive.png' alt='drive icon' width="100"></a>
                                </div>
                            </td>
                        </tr>
                        
                        <tr>
                            <td><a href='https://arxiv.org/abs/2306.14268' target="_blank">Paper</a></td>
                            <td><a href='https://github.com/LeiaLi/LMD-ViT' target="_blank">Code</a></td>
                            <td><a href='https://drive.google.com/drive/folders/1cBhtfm7vzsyAr9D6V_LwWJma845rUSlg?usp=sharing' target="_blank">Dataset</a></td>
                            
                        </tr>
                        
                    </table>
                </div> 
            
            <br>
            <section>
                <br>
                <p>We referred to the project page of <a href="https://a-vit.github.io/">A-ViT</a> when creating this
                    project page.</p>
            <!-- </section>
            <div class="paper">
            <div id="paper" class="wrapper-extra-links">
                <div class="extra-link">
                    <div class="paper-pic">
                        <span class="paper-title">Paper</span>
                        <figure>
                            <a target="_blank" href="https://arxiv.org/abs/2306.14268"><img src="./img_source/image/paper_cover.png" alt=""></a>
                        </figure>
                    </div>
                    <div class="description">
                        <p>
                            Adaptive Window Pruning for Efficient Local Motion Deblurring.
                        </p>
                        <a target="_blank" href="https://arxiv.org/abs/2306.14268">paper</a>
                    </div>
                </div> -->
            <!-- </div> -->

           <!-- </div>

            <div class="wrapper-code">
                <span class="title">Bibtex</span>
                    <pre>
            <div align="center">
    <code id="code">

    @inproceedings{yin2022avit,
        title={{A}-{V}i{T}: {A}daptive Tokens for Efficient Vision Transformer},
        author={Yin, Hongxu and Vahdat, Arash and Alvarez, Jose and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
        year={2022}
    }

    or

    @inproceedings{yin2022avit,
        title={{A}da{V}i{T}: {A}daptive Tokens for Efficient Vision Transformer},
        author={Yin, Hongxu and Vahdat, Arash and Alvarez, Jose and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo},
        booktitle={arXiv preprint arXiv:2112.07658},
        year={2021}
    } -->

                        <!-- </code>
                    </pre>
            </div>
        </div>
    </div>

    <script src="./dist/js/wow.min.js"></script>
    <script src="./dist/js/main.js"></script> -->
</body>
</html>
